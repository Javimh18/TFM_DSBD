{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/javiermunoz/Universidad/MasterDSyBD/TFM/TFM_DSBD'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# Changing the working directory\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc(\"figure\", figsize=(15, 5))\n",
    "\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import DATA_PATH, VIDEOS_PATH\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from config import SPLITS\n",
    "from numpy.random import default_rng\n",
    "import shutil\n",
    "import pathlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss_id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Opaque</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Red</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Green</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bright</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>Copy</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>Run</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>Realize</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>Give</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>Find</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gloss_id    gloss hand\n",
       "0          1   Opaque    R\n",
       "1          2      Red    R\n",
       "2          3    Green    R\n",
       "3          4   Yellow    R\n",
       "4          5   Bright    R\n",
       "..       ...      ...  ...\n",
       "59        60     Copy    B\n",
       "60        61      Run    B\n",
       "61        62  Realize    R\n",
       "62        63     Give    B\n",
       "63        64     Find    R\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the labels data\n",
    "labels = pd.read_csv('./data/labels.csv')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of videos in the dataset is: 3200\n"
     ]
    }
   ],
   "source": [
    "list_of_videos = os.listdir(VIDEOS_PATH)\n",
    "print(f\"The number of videos in the dataset is: {len(list_of_videos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>gloss_id</th>\n",
       "      <th>interpreter_id</th>\n",
       "      <th>take_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>008_010_003.mp4</td>\n",
       "      <td>8</td>\n",
       "      <td>010</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>023_001_003.mp4</td>\n",
       "      <td>23</td>\n",
       "      <td>001</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>039_003_005.mp4</td>\n",
       "      <td>39</td>\n",
       "      <td>003</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>051_005_002.mp4</td>\n",
       "      <td>51</td>\n",
       "      <td>005</td>\n",
       "      <td>002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010_007_001.mp4</td>\n",
       "      <td>10</td>\n",
       "      <td>007</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>045_006_003.mp4</td>\n",
       "      <td>45</td>\n",
       "      <td>006</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>033_005_001.mp4</td>\n",
       "      <td>33</td>\n",
       "      <td>005</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>031_010_005.mp4</td>\n",
       "      <td>31</td>\n",
       "      <td>010</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>021_009_001.mp4</td>\n",
       "      <td>21</td>\n",
       "      <td>009</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>037_002_002.mp4</td>\n",
       "      <td>37</td>\n",
       "      <td>002</td>\n",
       "      <td>002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             video_id  gloss_id interpreter_id take_id\n",
       "0     008_010_003.mp4         8            010     003\n",
       "1     023_001_003.mp4        23            001     003\n",
       "2     039_003_005.mp4        39            003     005\n",
       "3     051_005_002.mp4        51            005     002\n",
       "4     010_007_001.mp4        10            007     001\n",
       "...               ...       ...            ...     ...\n",
       "3195  045_006_003.mp4        45            006     003\n",
       "3196  033_005_001.mp4        33            005     001\n",
       "3197  031_010_005.mp4        31            010     005\n",
       "3198  021_009_001.mp4        21            009     001\n",
       "3199  037_002_002.mp4        37            002     002\n",
       "\n",
       "[3200 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a metadata dictionary\n",
    "metadata_dict = {\n",
    "    \"video_id\": [],\n",
    "    \"gloss_id\": [],\n",
    "    \"interpreter_id\": [],\n",
    "    \"take_id\": []\n",
    "}\n",
    "\n",
    "for video_id in list_of_videos:\n",
    "    str_splits = video_id.split(\"_\")\n",
    "    gloss_id, interpreter_id, take_id = int(str_splits[0]), str_splits[1], str_splits[2].split(\".\")[0]\n",
    "    metadata_dict[\"gloss_id\"].append(gloss_id)\n",
    "    metadata_dict[\"interpreter_id\"].append(interpreter_id)\n",
    "    metadata_dict[\"take_id\"].append(take_id)\n",
    "    metadata_dict[\"video_id\"].append(video_id)\n",
    "\n",
    "metadata_df = pd.DataFrame(metadata_dict)\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>gloss_id</th>\n",
       "      <th>interpreter_id</th>\n",
       "      <th>take_id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>008_010_003.mp4</td>\n",
       "      <td>8</td>\n",
       "      <td>010</td>\n",
       "      <td>003</td>\n",
       "      <td>Pink</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>008_008_005.mp4</td>\n",
       "      <td>8</td>\n",
       "      <td>008</td>\n",
       "      <td>005</td>\n",
       "      <td>Pink</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008_008_004.mp4</td>\n",
       "      <td>8</td>\n",
       "      <td>008</td>\n",
       "      <td>004</td>\n",
       "      <td>Pink</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>008_009_001.mp4</td>\n",
       "      <td>8</td>\n",
       "      <td>009</td>\n",
       "      <td>001</td>\n",
       "      <td>Pink</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>008_010_002.mp4</td>\n",
       "      <td>8</td>\n",
       "      <td>010</td>\n",
       "      <td>002</td>\n",
       "      <td>Pink</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>013_010_002.mp4</td>\n",
       "      <td>13</td>\n",
       "      <td>010</td>\n",
       "      <td>002</td>\n",
       "      <td>Away</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>013_009_001.mp4</td>\n",
       "      <td>13</td>\n",
       "      <td>009</td>\n",
       "      <td>001</td>\n",
       "      <td>Away</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>013_008_004.mp4</td>\n",
       "      <td>13</td>\n",
       "      <td>008</td>\n",
       "      <td>004</td>\n",
       "      <td>Away</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>013_008_005.mp4</td>\n",
       "      <td>13</td>\n",
       "      <td>008</td>\n",
       "      <td>005</td>\n",
       "      <td>Away</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>013_010_003.mp4</td>\n",
       "      <td>13</td>\n",
       "      <td>010</td>\n",
       "      <td>003</td>\n",
       "      <td>Away</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             video_id  gloss_id interpreter_id take_id gloss hand\n",
       "0     008_010_003.mp4         8            010     003  Pink    R\n",
       "1     008_008_005.mp4         8            008     005  Pink    R\n",
       "2     008_008_004.mp4         8            008     004  Pink    R\n",
       "3     008_009_001.mp4         8            009     001  Pink    R\n",
       "4     008_010_002.mp4         8            010     002  Pink    R\n",
       "...               ...       ...            ...     ...   ...  ...\n",
       "3195  013_010_002.mp4        13            010     002  Away    R\n",
       "3196  013_009_001.mp4        13            009     001  Away    R\n",
       "3197  013_008_004.mp4        13            008     004  Away    R\n",
       "3198  013_008_005.mp4        13            008     005  Away    R\n",
       "3199  013_010_003.mp4        13            010     003  Away    R\n",
       "\n",
       "[3200 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join both dictionaries\n",
    "full_metadata_df = metadata_df.merge(labels, on='gloss_id')\n",
    "full_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(video_id          False\n",
       " gloss_id          False\n",
       " interpreter_id    False\n",
       " take_id           False\n",
       " gloss             False\n",
       " hand              False\n",
       " dtype: bool,\n",
       " video_id          False\n",
       " gloss_id          False\n",
       " interpreter_id    False\n",
       " take_id           False\n",
       " gloss             False\n",
       " hand              False\n",
       " dtype: bool)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that there are no nulls\n",
    "full_metadata_df.isnull().any(), full_metadata_df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_4_train, metadata_4_test = train_test_split(full_metadata_df, test_size=0.2, shuffle=True)\n",
    "metadata_4_val, metadata_4_test = train_test_split(metadata_4_test, test_size=0.4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>gloss_id</th>\n",
       "      <th>interpreter_id</th>\n",
       "      <th>take_id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>hand</th>\n",
       "      <th>sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>024_005_002.mp4</td>\n",
       "      <td>24</td>\n",
       "      <td>005</td>\n",
       "      <td>002</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>R</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>063_008_002.mp4</td>\n",
       "      <td>63</td>\n",
       "      <td>008</td>\n",
       "      <td>002</td>\n",
       "      <td>Give</td>\n",
       "      <td>B</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>063_007_002.mp4</td>\n",
       "      <td>63</td>\n",
       "      <td>007</td>\n",
       "      <td>002</td>\n",
       "      <td>Give</td>\n",
       "      <td>B</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>044_001_003.mp4</td>\n",
       "      <td>44</td>\n",
       "      <td>001</td>\n",
       "      <td>003</td>\n",
       "      <td>Rice</td>\n",
       "      <td>B</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>060_005_002.mp4</td>\n",
       "      <td>60</td>\n",
       "      <td>005</td>\n",
       "      <td>002</td>\n",
       "      <td>Copy</td>\n",
       "      <td>B</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>001_007_003.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>007</td>\n",
       "      <td>003</td>\n",
       "      <td>Opaque</td>\n",
       "      <td>R</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>059_003_003.mp4</td>\n",
       "      <td>59</td>\n",
       "      <td>003</td>\n",
       "      <td>003</td>\n",
       "      <td>Buy</td>\n",
       "      <td>R</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>013_002_005.mp4</td>\n",
       "      <td>13</td>\n",
       "      <td>002</td>\n",
       "      <td>005</td>\n",
       "      <td>Away</td>\n",
       "      <td>R</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>012_009_005.mp4</td>\n",
       "      <td>12</td>\n",
       "      <td>009</td>\n",
       "      <td>005</td>\n",
       "      <td>Man</td>\n",
       "      <td>R</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>038_009_003.mp4</td>\n",
       "      <td>38</td>\n",
       "      <td>009</td>\n",
       "      <td>003</td>\n",
       "      <td>None</td>\n",
       "      <td>R</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             video_id  gloss_id interpreter_id take_id      gloss hand     sp\n",
       "3058  024_005_002.mp4        24            005     002  Argentina    R  train\n",
       "2587  063_008_002.mp4        63            008     002       Give    B  train\n",
       "2566  063_007_002.mp4        63            007     002       Give    B  train\n",
       "638   044_001_003.mp4        44            001     003       Rice    B  train\n",
       "368   060_005_002.mp4        60            005     002       Copy    B  train\n",
       "...               ...       ...            ...     ...        ...  ...    ...\n",
       "731   001_007_003.mp4         1            007     003     Opaque    R   test\n",
       "2851  059_003_003.mp4        59            003     003        Buy    R   test\n",
       "3179  013_002_005.mp4        13            002     005       Away    R   test\n",
       "575   012_009_005.mp4        12            009     005        Man    R   test\n",
       "3038  038_009_003.mp4        38            009     003       None    R   test\n",
       "\n",
       "[3200 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_4_train[\"sp\"] = 'train'\n",
    "metadata_4_val[\"sp\"] = 'val'\n",
    "metadata_4_test[\"sp\"] = 'test'\n",
    "full_metadata_df = pd.concat([metadata_4_train, metadata_4_val, metadata_4_test])\n",
    "full_metadata_df.reset_index()\n",
    "full_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>gloss_id</th>\n",
       "      <th>interpreter_id</th>\n",
       "      <th>take_id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>hand</th>\n",
       "      <th>sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>063_008_002.mp4</td>\n",
       "      <td>63</td>\n",
       "      <td>008</td>\n",
       "      <td>002</td>\n",
       "      <td>Give</td>\n",
       "      <td>B</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>063_007_002.mp4</td>\n",
       "      <td>63</td>\n",
       "      <td>007</td>\n",
       "      <td>002</td>\n",
       "      <td>Give</td>\n",
       "      <td>B</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>056_005_002.mp4</td>\n",
       "      <td>56</td>\n",
       "      <td>005</td>\n",
       "      <td>002</td>\n",
       "      <td>Help</td>\n",
       "      <td>B</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>033_010_004.mp4</td>\n",
       "      <td>33</td>\n",
       "      <td>010</td>\n",
       "      <td>004</td>\n",
       "      <td>Hungry</td>\n",
       "      <td>R</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>061_007_002.mp4</td>\n",
       "      <td>61</td>\n",
       "      <td>007</td>\n",
       "      <td>002</td>\n",
       "      <td>Run</td>\n",
       "      <td>B</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>056_010_002.mp4</td>\n",
       "      <td>56</td>\n",
       "      <td>010</td>\n",
       "      <td>002</td>\n",
       "      <td>Help</td>\n",
       "      <td>B</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>027_002_005.mp4</td>\n",
       "      <td>27</td>\n",
       "      <td>002</td>\n",
       "      <td>005</td>\n",
       "      <td>Last name</td>\n",
       "      <td>R</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>027_006_003.mp4</td>\n",
       "      <td>27</td>\n",
       "      <td>006</td>\n",
       "      <td>003</td>\n",
       "      <td>Last name</td>\n",
       "      <td>R</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>053_004_004.mp4</td>\n",
       "      <td>53</td>\n",
       "      <td>004</td>\n",
       "      <td>004</td>\n",
       "      <td>Appear</td>\n",
       "      <td>B</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>059_003_003.mp4</td>\n",
       "      <td>59</td>\n",
       "      <td>003</td>\n",
       "      <td>003</td>\n",
       "      <td>Buy</td>\n",
       "      <td>R</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             video_id  gloss_id interpreter_id take_id      gloss hand     sp\n",
       "2587  063_008_002.mp4        63            008     002       Give    B  train\n",
       "2566  063_007_002.mp4        63            007     002       Give    B  train\n",
       "798   056_005_002.mp4        56            005     002       Help    B  train\n",
       "1367  033_010_004.mp4        33            010     004     Hungry    R  train\n",
       "836   061_007_002.mp4        61            007     002        Run    B  train\n",
       "...               ...       ...            ...     ...        ...  ...    ...\n",
       "752   056_010_002.mp4        56            010     002       Help    B   test\n",
       "1649  027_002_005.mp4        27            002     005  Last name    R   test\n",
       "1603  027_006_003.mp4        27            006     003  Last name    R   test\n",
       "1492  053_004_004.mp4        53            004     004     Appear    B   test\n",
       "2851  059_003_003.mp4        59            003     003        Buy    R   test\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we take a subset of classes from the whole dataset\n",
    "rng = default_rng()\n",
    "subset_size = 10\n",
    "subset_labels = rng.choice(len(labels), size=subset_size, replace=False)\n",
    "\n",
    "subset_metadata_df = full_metadata_df[full_metadata_df['gloss_id'].isin(subset_labels)]\n",
    "subset_metadata_df.reset_index()\n",
    "subset_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "erase_original = False\n",
    "subset = f\"subset_{subset_size}_lsa_64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# iterate through rows of the dataset\n",
    "for index, row in subset_metadata_df.iterrows():\n",
    "    source = os.path.join(VIDEOS_PATH, row['video_id'])\n",
    "    destination = os.path.join(DATA_PATH, subset, row['sp'], row['gloss'])\n",
    "\n",
    "    # create the dataset structure /data/videos/<train|test|val>/gloss\n",
    "    if not os.path.exists(destination): \n",
    "        os.makedirs(destination)\n",
    "\n",
    "    # and now, we copy from /data/videos to /data/subset_{subset_size}_lsa_64/<train|test|val>/gloss\n",
    "    if os.path.exists(source):\n",
    "        shutil.copy(source, destination)\n",
    "\n",
    "    if erase_original:\n",
    "        os.remove(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_paths = {}\n",
    "for sp in SPLITS:\n",
    "    subset_paths[sp] = pathlib.Path(os.path.join(DATA_PATH, subset, sp))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import vidaug.augmentors as va \n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from augment_dataset import video_loader, data_transformer, from_PIL_to_opencv\n",
    "MAX_AUG = 1\n",
    "\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_aument = random.randint(0, MAX_AUG)\n",
    "subset_path = os.path.join(DATA_PATH, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:48<00:00, 64.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:19<00:00,  7.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val split processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:08<00:00,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test split processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for sp in SPLITS:\n",
    "    for gloss in tqdm(os.listdir(os.path.join(subset_path, sp))):\n",
    "        for video_name in os.listdir(os.path.join(subset_path, sp, gloss)):\n",
    "            for i in range(to_aument):\n",
    "                video_path = os.path.join(subset_path, sp, gloss, video_name)\n",
    "                # get metadata from the video and encoding the output\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                fourCC = cv2.VideoWriter_fourcc(\"m\", \"p\", \"4\", \"v\")\n",
    "                # retrieve frames as PIL images\n",
    "                frames = video_loader(video_path)\n",
    "                # get frame width and height\n",
    "                frame_width, frame_height = frames[0].size\n",
    "\n",
    "                vid_name = video_name.split(\".\")[0]\n",
    "                aug_vid_name = f\"{vid_name}_aug{i}.mp4\"\n",
    "                aug_frames = data_transformer(frames, frame_height, frame_width, crop_factor=0.2)\n",
    "                new_frame_width, new_frame_height = aug_frames[0].size\n",
    "                cv2_frames = from_PIL_to_opencv(aug_frames)  \n",
    "                path_out = os.path.join(subset_path, sp, gloss, aug_vid_name)\n",
    "                out = cv2.VideoWriter(path_out, fourCC, fps, (new_frame_width, new_frame_height))\n",
    "\n",
    "                for frame in cv2_frames:\n",
    "                    out.write(frame)\n",
    "\n",
    "                out.release()\n",
    "                cap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Video Dataset\n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_dataset_aux import frames_from_video_file, to_gif\n",
    "from frame_generator import FrameGenerator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"./data/subset_10_lsa_64/train/Give/063_008_002.mp4\"\n",
      "2023-04-19 10:11:06.932953: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m idx, row \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(subset_metadata_df\u001b[39m.\u001b[39miterrows())\n\u001b[0;32m----> 3\u001b[0m ucf_sample_video \u001b[39m=\u001b[39m frames_from_video_file(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(subset_path, row[\u001b[39m'\u001b[39;49m\u001b[39msp\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39mgloss\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39mvideo_id\u001b[39;49m\u001b[39m'\u001b[39;49m]), \u001b[39m10\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m to_gif(ucf_sample_video)\n",
      "File \u001b[0;32m~/Universidad/MasterDSyBD/TFM/TFM_DSBD/src/load_dataset_aux.py:55\u001b[0m, in \u001b[0;36mframes_from_video_file\u001b[0;34m(video_path, n_frames, output_size, frame_step)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m# ret is a boolean indicating whether read was successful, frame is the image itself\u001b[39;00m\n\u001b[1;32m     54\u001b[0m ret, frame \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mread()\n\u001b[0;32m---> 55\u001b[0m result\u001b[39m.\u001b[39mappend(format_frames(frame, output_size))\n\u001b[1;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_frames \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     58\u001b[0m   \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(frame_step):\n",
      "File \u001b[0;32m~/Universidad/MasterDSyBD/TFM/TFM_DSBD/src/load_dataset_aux.py:22\u001b[0m, in \u001b[0;36mformat_frames\u001b[0;34m(frame, output_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_frames\u001b[39m(frame, output_size):\n\u001b[1;32m     12\u001b[0m   \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m    Pad and resize an image from a video.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m      Formatted frame with padding of specified output size.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m   frame \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mconvert_image_dtype(frame, tf\u001b[39m.\u001b[39;49mfloat32)\n\u001b[1;32m     23\u001b[0m   frame \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mresize_with_pad(frame, \u001b[39m*\u001b[39moutput_size)\n\u001b[1;32m     24\u001b[0m   \u001b[39mreturn\u001b[39;00m frame\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev-ml-environment/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev-ml-environment/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "idx, row = next(subset_metadata_df.iterrows())\n",
    "\n",
    "ucf_sample_video = frames_from_video_file(os.path.join(subset_path, row['sp'], row['gloss'], row['video_id']), 10)\n",
    "to_gif(ucf_sample_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 224, 224, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucf_sample_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10, 224, 224, 3)\n",
      "Label: 4\n"
     ]
    }
   ],
   "source": [
    "fg = FrameGenerator(subset_paths['train'], 10, training=True)\n",
    "\n",
    "frames, label = next(fg())\n",
    "print(f\"Shape: {frames.shape}\")\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 10\n",
    "batch_size = 8\n",
    "\n",
    "# We specify the shape of the output, such as, the Generator will produce a tuple of both\n",
    "# videos, class, where the videos will have 3 channels, and the rest of dimensions will remain the same.\n",
    "#   VideoShape -> (F, H, W, C)\n",
    "output_signature = (tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(), dtype=tf.int16))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['train'], n_frames, training=True),\n",
    "                                          output_signature=output_signature)\n",
    "# Also, we batchify the data, so the training process is not as memory consuming as if the whole dataset was \n",
    "# loaded into memory.\n",
    "# VideoShape -> (B, F, H, W, C)\n",
    "# train_ds = train_ds.batch(batch_size)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "# We reproduce this process for the validation and test splits too.\n",
    "val_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['val'], n_frames),\n",
    "                                        output_signature=output_signature)\n",
    "\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['test'], n_frames),\n",
    "                                         output_signature=output_signature)\n",
    "\n",
    "test_ds = test_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAUTOTUNE = tf.data.AUTOTUNE\\n\\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\\nval_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set of frames: (8, 10, 224, 224, 3)\n",
      "Shape of training labels: (8,)\n",
      "Shape of validation set of frames: (8, 10, 224, 224, 3)\n",
      "Shape of validation labels: (8,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the data\n",
    "train_frames, train_labels = next(iter(train_ds))\n",
    "print(f'Shape of training set of frames: {train_frames.shape}')\n",
    "print(f'Shape of training labels: {train_labels.shape}')\n",
    "\n",
    "val_frames, val_labels = next(iter(val_ds))\n",
    "print(f'Shape of validation set of frames: {val_frames.shape}')\n",
    "print(f'Shape of validation labels: {val_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 224, 224, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(None, *train_frames.shape[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model definition and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d (ConvLSTM2D)    (None, None, 224, 224, 6  154624    \n",
      "                             4)                                  \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, 224, 224, 6  256      \n",
      " ormalization)               4)                                  \n",
      "                                                                 \n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, None, 224, 224, 6  295168    \n",
      "                             4)                                  \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, None, 224, 224, 6  256      \n",
      " hNormalization)             4)                                  \n",
      "                                                                 \n",
      " conv_lstm2d_2 (ConvLSTM2D)  (None, None, 224, 224, 6  295168    \n",
      "                             4)                                  \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, None, 224, 224, 6  256      \n",
      " hNormalization)             4)                                  \n",
      "                                                                 \n",
      " global_average_pooling3d (G  (None, 64)               0         \n",
      " lobalAveragePooling3D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 748,138\n",
      "Trainable params: 747,754\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Construct the input layer with no definite frame size.\n",
    "    tf.keras.layers.InputLayer(input_shape=(None, *train_frames.shape[2:])),\n",
    "    # We will construct 3 `ConvLSTM2D` layers with batch normalization,\n",
    "    tf.keras.layers.ConvLSTM2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        return_sequences=True,\n",
    "        activation=\"relu\",\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ConvLSTM2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        return_sequences=True,\n",
    "        activation=\"relu\",\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ConvLSTM2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        return_sequences=True,\n",
    "        activation=\"relu\",\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.GlobalAveragePooling3D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=10, activation='sigmoid')\n",
    "])\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, \n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 10), dtype=float32, numpy=\n",
       "array([[0.4999846 , 0.5009533 , 0.49899152, 0.49938366, 0.499421  ,\n",
       "        0.49976066, 0.49939665, 0.50138026, 0.49955982, 0.4994986 ],\n",
       "       [0.49998364, 0.5009526 , 0.49899235, 0.49938452, 0.49942103,\n",
       "        0.4997609 , 0.49939695, 0.5013791 , 0.49956113, 0.4994995 ],\n",
       "       [0.49998257, 0.5009524 , 0.49899366, 0.49938482, 0.49942034,\n",
       "        0.49976227, 0.49939784, 0.50137985, 0.49956268, 0.49949962],\n",
       "       [0.49998203, 0.5009522 , 0.49899274, 0.4993849 , 0.49942032,\n",
       "        0.49976173, 0.49939808, 0.5013791 , 0.49956247, 0.4994996 ],\n",
       "       [0.49998263, 0.5009525 , 0.49899223, 0.49938464, 0.49942067,\n",
       "        0.4997615 , 0.4993976 , 0.50137955, 0.49956167, 0.4994992 ],\n",
       "       [0.49998346, 0.50095254, 0.4989926 , 0.49938434, 0.49942076,\n",
       "        0.49976113, 0.4993975 , 0.50137925, 0.4995612 , 0.49949938],\n",
       "       [0.4999823 , 0.50095296, 0.49899194, 0.49938428, 0.4994203 ,\n",
       "        0.4997616 , 0.49939743, 0.5013803 , 0.49956197, 0.49949902],\n",
       "       [0.49998412, 0.5009523 , 0.49899217, 0.49938428, 0.4994212 ,\n",
       "        0.49976042, 0.49939737, 0.50137824, 0.49956042, 0.49949956]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_video = tf.random.uniform((8, 10, 224, 224, 3))\n",
    "model(random_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = tf.keras.layers.ConvLSTM2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        return_sequences=True,\n",
    "        activation=\"relu\",\n",
    "    )\n",
    "\n",
    "conv2d(train_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "# Define some callbacks to improve training.\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Define modifiable training hyperparameters.\n",
    "epochs = 20\n",
    "\n",
    "# Fit the model to the training data using a generator.\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-ml-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39ae795c3b6613b3a9cfc085ce713292b6eefc863ced5f4a8404447c67e159c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
