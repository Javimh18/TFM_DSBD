{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/javiermunoz/Universidad/MasterBDyDS/TFM/TFM_DSBD'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# Changing the working directory\n",
    "os.chdir('../..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javiermunoz/anaconda3/envs/tf/lib/python3.9/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc(\"figure\", figsize=(15, 5))\n",
    "\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import DATA_PATH, SPLITS\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = 10\n",
    "subset = f\"subset_{subset_size}_lsa_64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_paths = {}\n",
    "for sp in SPLITS:\n",
    "    subset_paths[sp] = pathlib.Path(os.path.join(DATA_PATH, subset, sp))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Video Dataset\n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_dataset_aux import frames_from_video_file, to_gif\n",
    "from frame_generator import FrameGenerator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10, 224, 224, 3)\n",
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "fg = FrameGenerator(subset_paths['train'], 10, training=True)\n",
    "\n",
    "frames, label = next(fg())\n",
    "print(f\"Shape: {frames.shape}\")\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 10\n",
    "batch_size = 8\n",
    "\n",
    "# We specify the shape of the output, such as, the Generator will produce a tuple of both\n",
    "# videos, class, where the videos will have 3 channels, and the rest of dimensions will remain the same.\n",
    "#   VideoShape -> (F, H, W, C)\n",
    "output_signature = (tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(), dtype=tf.int16))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['train'], n_frames, training=True),\n",
    "                                          output_signature=output_signature)\n",
    "# Also, we batchify the data, so the training process is not as memory consuming as if the whole dataset was \n",
    "# loaded into memory.\n",
    "# VideoShape -> (B, F, H, W, C)\n",
    "# train_ds = train_ds.batch(batch_size)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "# We reproduce this process for the validation and test splits too.\n",
    "val_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['val'], n_frames),\n",
    "                                        output_signature=output_signature)\n",
    "\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['test'], n_frames),\n",
    "                                         output_signature=output_signature)\n",
    "\n",
    "test_ds = test_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set of frames: (8, 10, 224, 224, 3)\n",
      "Shape of training labels: (8,)\n",
      "Shape of validation set of frames: (8, 10, 224, 224, 3)\n",
      "Shape of validation labels: (8,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the data\n",
    "train_frames, train_labels = next(iter(train_ds))\n",
    "print(f'Shape of training set of frames: {train_frames.shape}')\n",
    "print(f'Shape of training labels: {train_labels.shape}')\n",
    "\n",
    "val_frames, val_labels = next(iter(val_ds))\n",
    "print(f'Shape of validation set of frames: {val_frames.shape}')\n",
    "print(f'Shape of validation labels: {val_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 224, 224, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(None, *train_frames.shape[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model definition and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, None, 224, 224, 3  0         \n",
      "                             )                                   \n",
      "                                                                 \n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, 222, 222, 16)      11008     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 222, 222, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 110, 110, 16)      2320      \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 110, 110, 16)      0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 16)               0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,562\n",
      "Trainable params: 13,530\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Construct the input layer with no definite frame size.\n",
    "    tf.keras.layers.InputLayer(input_shape=(None, *train_frames.shape[2:])),\n",
    "    # Reescale the values of the pixels (per frame)\n",
    "    tf.keras.layers.Rescaling(scale=255),\n",
    "    # We will construct 3 `ConvLSTM2D` layers with batch normalization,\n",
    "    tf.keras.layers.ConvLSTM2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1,1),\n",
    "        stateful=True,\n",
    "        return_sequences=False,\n",
    "        activation=\"relu\",\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ConvLSTM2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(2,2),\n",
    "        stateful=True,\n",
    "        return_sequences=True,\n",
    "        activation=\"relu\",\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ConvLSTM2D(\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1,1),\n",
    "        stateful=True,\n",
    "        return_sequences=False,\n",
    "        activation=\"relu\",\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=256,\n",
    "        kernel_size=(3,3),                       \n",
    "        strides=(2,2),\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=(3,3),                       \n",
    "        strides=(2,2),\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3,3),                       \n",
    "        strides=(2,2),\n",
    "    ),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, \n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, expand_nested=True, dpi=60, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some callbacks to improve training.\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define modifiable training hyperparameters.\n",
    "epochs = 60\n",
    "\n",
    "# Fit the model to the training data using a generator.\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_ds, batch_size=batch_size)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-ml-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39ae795c3b6613b3a9cfc085ce713292b6eefc863ced5f4a8404447c67e159c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
