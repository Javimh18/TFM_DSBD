{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/javiermunoz/Universidad/MasterBDyDS/TFM/TFM_DSBD'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# Changing the working directory\n",
    "os.chdir('../..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javiermunoz/anaconda3/envs/tf/lib/python3.9/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc(\"figure\", figsize=(15, 5))\n",
    "\n",
    "import os \n",
    "from src.config import DATA_PATH, SPLITS\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = 10\n",
    "subset = f\"subset_{subset_size}_lsa_64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_paths = {}\n",
    "for sp in SPLITS:\n",
    "    subset_paths[sp] = pathlib.Path(os.path.join(DATA_PATH, subset, sp))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Video Dataset\n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.frame_generator import FrameGenerator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10, 224, 224, 3)\n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "fg = FrameGenerator(subset_paths['train'], 10, training=True)\n",
    "\n",
    "frames, label = next(fg())\n",
    "print(f\"Shape: {frames.shape}\")\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 10\n",
    "batch_size = 8\n",
    "\n",
    "# We specify the shape of the output, such as, the Generator will produce a tuple of both\n",
    "# videos, class, where the videos will have 3 channels, and the rest of dimensions will remain the same.\n",
    "#   VideoShape -> (F, H, W, C)\n",
    "output_signature = (tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(), dtype=tf.int16))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['train'], n_frames, training=True),\n",
    "                                          output_signature=output_signature)\n",
    "# Also, we batchify the data, so the training process is not as memory consuming as if the whole dataset was \n",
    "# loaded into memory.\n",
    "# VideoShape -> (B, F, H, W, C)\n",
    "# train_ds = train_ds.batch(batch_size)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "# We reproduce this process for the validation and test splits too.\n",
    "val_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['val'], n_frames),\n",
    "                                        output_signature=output_signature)\n",
    "\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['test'], n_frames),\n",
    "                                         output_signature=output_signature)\n",
    "\n",
    "test_ds = test_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set of frames: (8, 10, 224, 224, 3)\n",
      "Shape of training labels: (8,)\n",
      "Shape of validation set of frames: (8, 10, 224, 224, 3)\n",
      "Shape of validation labels: (8,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the data\n",
    "train_frames, train_labels = next(iter(train_ds))\n",
    "print(f'Shape of training set of frames: {train_frames.shape}')\n",
    "print(f'Shape of training labels: {train_labels.shape}')\n",
    "\n",
    "val_frames, val_labels = next(iter(val_ds))\n",
    "print(f'Shape of validation set of frames: {val_frames.shape}')\n",
    "print(f'Shape of validation labels: {val_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 224, 224, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(None, *train_frames.shape[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model definition and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_2 (Rescaling)     (None, None, 224, 224, 3  0         \n",
      "                             )                                   \n",
      "                                                                 \n",
      " conv_lstm2d_4 (ConvLSTM2D)  (None, None, 222, 222, 1  11008     \n",
      "                             6)                                  \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, None, 222, 222, 1  64       \n",
      " hNormalization)             6)                                  \n",
      "                                                                 \n",
      " conv_lstm2d_5 (ConvLSTM2D)  (None, 220, 220, 8)       6944      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 220, 220, 8)      32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 218, 218, 16)      1168      \n",
      "                                                                 \n",
      " global_max_pooling2d_2 (Glo  (None, 16)               0         \n",
      " balMaxPooling2D)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,386\n",
      "Trainable params: 19,338\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Construct the input layer with no definite frame size.\n",
    "    tf.keras.layers.InputLayer(input_shape=(None, *train_frames.shape[2:])),\n",
    "    # Reescale the values of the pixels (per frame)\n",
    "    tf.keras.layers.Rescaling(scale=255),\n",
    "    # We will construct 3 `ConvLSTM2D` layers with batch normalization,\n",
    "    tf.keras.layers.ConvLSTM2D(\n",
    "        filters=16,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1,1),\n",
    "        stateful=False,\n",
    "        return_sequences=True,\n",
    "        activation=\"tanh\",\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ConvLSTM2D(\n",
    "        filters=8,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1,1),\n",
    "        stateful=False,\n",
    "        return_sequences=False,\n",
    "        activation=\"tanh\",\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=16,\n",
    "        kernel_size=(3,3),                       \n",
    "        strides=(1,1),\n",
    "    ),\n",
    "    tf.keras.layers.GlobalMaxPooling2D(),\n",
    "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, \n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-03),\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "50/50 [==============================] - 29s 531ms/step - loss: 3.2642 - acc: 0.1294 - val_loss: 2.3583 - val_acc: 0.0333\n",
      "Epoch 2/80\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 2.2327 - acc: 0.1954 - val_loss: 2.2967 - val_acc: 0.1000\n",
      "Epoch 3/80\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 2.0487 - acc: 0.2538 - val_loss: 2.2369 - val_acc: 0.1833\n",
      "Epoch 4/80\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 1.8460 - acc: 0.3198 - val_loss: 2.0954 - val_acc: 0.2667\n",
      "Epoch 5/80\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 1.7358 - acc: 0.3832 - val_loss: 1.9181 - val_acc: 0.2500\n",
      "Epoch 6/80\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 1.6049 - acc: 0.4492 - val_loss: 1.7088 - val_acc: 0.4000\n",
      "Epoch 7/80\n",
      "50/50 [==============================] - 26s 532ms/step - loss: 1.5004 - acc: 0.4315 - val_loss: 1.5430 - val_acc: 0.4000\n",
      "Epoch 8/80\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 1.4172 - acc: 0.4442 - val_loss: 1.7341 - val_acc: 0.3000\n",
      "Epoch 9/80\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 1.4872 - acc: 0.4416 - val_loss: 1.7599 - val_acc: 0.3500\n",
      "Epoch 10/80\n",
      "50/50 [==============================] - 26s 530ms/step - loss: 1.3915 - acc: 0.4822 - val_loss: 1.4487 - val_acc: 0.3833\n",
      "Epoch 11/80\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 1.2862 - acc: 0.4772 - val_loss: 1.3783 - val_acc: 0.3500\n",
      "Epoch 12/80\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 1.2777 - acc: 0.4746 - val_loss: 1.4367 - val_acc: 0.3833\n",
      "Epoch 13/80\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 1.2500 - acc: 0.4873 - val_loss: 1.5582 - val_acc: 0.3500\n",
      "Epoch 14/80\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 1.4509 - acc: 0.4645 - val_loss: 1.4129 - val_acc: 0.4667\n",
      "Epoch 15/80\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 1.1768 - acc: 0.5558 - val_loss: 1.3198 - val_acc: 0.4167\n",
      "Epoch 16/80\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 1.1402 - acc: 0.5685 - val_loss: 1.2926 - val_acc: 0.4833\n",
      "Epoch 17/80\n",
      "50/50 [==============================] - 27s 541ms/step - loss: 1.3670 - acc: 0.4619 - val_loss: 1.4841 - val_acc: 0.4500\n",
      "Epoch 18/80\n",
      "50/50 [==============================] - 27s 535ms/step - loss: 1.0659 - acc: 0.5914 - val_loss: 1.1918 - val_acc: 0.5833\n",
      "Epoch 19/80\n",
      "50/50 [==============================] - 27s 532ms/step - loss: 0.8849 - acc: 0.6701 - val_loss: 1.2038 - val_acc: 0.4500\n",
      "Epoch 20/80\n",
      "50/50 [==============================] - 27s 531ms/step - loss: 0.8549 - acc: 0.6320 - val_loss: 1.2249 - val_acc: 0.5500\n",
      "Epoch 21/80\n",
      "50/50 [==============================] - 27s 537ms/step - loss: 0.9039 - acc: 0.6624 - val_loss: 1.1624 - val_acc: 0.5167\n",
      "Epoch 22/80\n",
      "50/50 [==============================] - 27s 537ms/step - loss: 0.9325 - acc: 0.6168 - val_loss: 0.9958 - val_acc: 0.5333\n",
      "Epoch 23/80\n",
      "50/50 [==============================] - 27s 538ms/step - loss: 0.7555 - acc: 0.7132 - val_loss: 0.8421 - val_acc: 0.6833\n",
      "Epoch 24/80\n",
      "50/50 [==============================] - 26s 529ms/step - loss: 0.6829 - acc: 0.7386 - val_loss: 1.0684 - val_acc: 0.5500\n",
      "Epoch 25/80\n",
      "50/50 [==============================] - 26s 530ms/step - loss: 0.5996 - acc: 0.7665 - val_loss: 0.8873 - val_acc: 0.6833\n",
      "Epoch 26/80\n",
      "50/50 [==============================] - 26s 530ms/step - loss: 0.7973 - acc: 0.7208 - val_loss: 1.0771 - val_acc: 0.5667\n",
      "Epoch 27/80\n",
      "50/50 [==============================] - 27s 537ms/step - loss: 0.7725 - acc: 0.7183 - val_loss: 0.8648 - val_acc: 0.6167\n",
      "Epoch 28/80\n",
      "50/50 [==============================] - 27s 536ms/step - loss: 0.9352 - acc: 0.6701 - val_loss: 0.9463 - val_acc: 0.5500\n",
      "Epoch 29/80\n",
      "50/50 [==============================] - 27s 534ms/step - loss: 0.8001 - acc: 0.6904 - val_loss: 0.9900 - val_acc: 0.6833\n",
      "Epoch 30/80\n",
      "50/50 [==============================] - 27s 537ms/step - loss: 0.6202 - acc: 0.7690 - val_loss: 0.8793 - val_acc: 0.6833\n",
      "Epoch 31/80\n",
      "50/50 [==============================] - 27s 536ms/step - loss: 0.5062 - acc: 0.8122 - val_loss: 0.9007 - val_acc: 0.7000\n",
      "Epoch 32/80\n",
      "50/50 [==============================] - 27s 539ms/step - loss: 0.4951 - acc: 0.8350 - val_loss: 0.8349 - val_acc: 0.7000\n",
      "Epoch 33/80\n",
      "50/50 [==============================] - 27s 545ms/step - loss: 0.4132 - acc: 0.8680 - val_loss: 0.8200 - val_acc: 0.6833\n",
      "Epoch 34/80\n",
      "50/50 [==============================] - 27s 537ms/step - loss: 0.4613 - acc: 0.8198 - val_loss: 1.0026 - val_acc: 0.6500\n",
      "Epoch 35/80\n",
      "50/50 [==============================] - 27s 541ms/step - loss: 0.5254 - acc: 0.8020 - val_loss: 1.0210 - val_acc: 0.6667\n",
      "Epoch 36/80\n",
      "50/50 [==============================] - 27s 536ms/step - loss: 0.6349 - acc: 0.7893 - val_loss: 1.2312 - val_acc: 0.6333\n",
      "Epoch 37/80\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 0.6711 - acc: 0.7589 - val_loss: 1.0435 - val_acc: 0.6500\n",
      "Epoch 38/80\n",
      "50/50 [==============================] - 26s 518ms/step - loss: 0.6395 - acc: 0.8046 - val_loss: 1.0614 - val_acc: 0.6333\n",
      "Epoch 39/80\n",
      "50/50 [==============================] - 26s 530ms/step - loss: 0.5073 - acc: 0.8147 - val_loss: 0.7271 - val_acc: 0.7000\n",
      "Epoch 40/80\n",
      "50/50 [==============================] - 27s 530ms/step - loss: 0.4264 - acc: 0.8503 - val_loss: 0.8756 - val_acc: 0.6000\n",
      "Epoch 41/80\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 0.3948 - acc: 0.8528 - val_loss: 0.6667 - val_acc: 0.7667\n",
      "Epoch 42/80\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 0.3808 - acc: 0.8629 - val_loss: 0.5905 - val_acc: 0.7333\n",
      "Epoch 43/80\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 0.2934 - acc: 0.8832 - val_loss: 0.6266 - val_acc: 0.7833\n",
      "Epoch 44/80\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 0.3282 - acc: 0.8807 - val_loss: 1.3003 - val_acc: 0.5333\n",
      "Epoch 45/80\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 0.4698 - acc: 0.8223 - val_loss: 0.6427 - val_acc: 0.7833\n",
      "Epoch 46/80\n",
      "50/50 [==============================] - 26s 520ms/step - loss: 0.3490 - acc: 0.8883 - val_loss: 0.5882 - val_acc: 0.8167\n",
      "Epoch 47/80\n",
      "50/50 [==============================] - 26s 519ms/step - loss: 0.4619 - acc: 0.8426 - val_loss: 0.8638 - val_acc: 0.6500\n",
      "Epoch 48/80\n",
      "50/50 [==============================] - 26s 520ms/step - loss: 0.4299 - acc: 0.8655 - val_loss: 0.5678 - val_acc: 0.8000\n",
      "Epoch 49/80\n",
      "50/50 [==============================] - 26s 518ms/step - loss: 0.3877 - acc: 0.8604 - val_loss: 0.5341 - val_acc: 0.8167\n",
      "Epoch 50/80\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 0.2561 - acc: 0.9112 - val_loss: 0.4450 - val_acc: 0.8000\n",
      "Epoch 51/80\n",
      "50/50 [==============================] - 26s 514ms/step - loss: 0.2406 - acc: 0.9162 - val_loss: 0.6497 - val_acc: 0.8167\n",
      "Epoch 52/80\n",
      "50/50 [==============================] - 26s 511ms/step - loss: 0.2199 - acc: 0.9188 - val_loss: 0.5427 - val_acc: 0.7500\n",
      "Epoch 53/80\n",
      "50/50 [==============================] - 26s 514ms/step - loss: 0.1926 - acc: 0.9365 - val_loss: 0.6140 - val_acc: 0.7667\n",
      "Epoch 54/80\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 0.2272 - acc: 0.9289 - val_loss: 0.4748 - val_acc: 0.8167\n",
      "Epoch 55/80\n",
      "50/50 [==============================] - 26s 517ms/step - loss: 0.4770 - acc: 0.8680 - val_loss: 0.4609 - val_acc: 0.8667\n",
      "Epoch 56/80\n",
      "50/50 [==============================] - 26s 512ms/step - loss: 0.2896 - acc: 0.9036 - val_loss: 0.5324 - val_acc: 0.8333\n",
      "Epoch 57/80\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 0.3432 - acc: 0.8934 - val_loss: 0.6937 - val_acc: 0.7667\n",
      "Epoch 58/80\n",
      "50/50 [==============================] - 26s 511ms/step - loss: 0.3099 - acc: 0.9010 - val_loss: 0.6798 - val_acc: 0.7667\n",
      "Epoch 59/80\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 0.1583 - acc: 0.9594 - val_loss: 0.4364 - val_acc: 0.8333\n",
      "Epoch 60/80\n",
      "50/50 [==============================] - 26s 512ms/step - loss: 0.1629 - acc: 0.9518 - val_loss: 0.5108 - val_acc: 0.8000\n",
      "Epoch 61/80\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 0.1130 - acc: 0.9619 - val_loss: 0.4153 - val_acc: 0.8500\n",
      "Epoch 62/80\n",
      "50/50 [==============================] - 26s 522ms/step - loss: 0.1502 - acc: 0.9467 - val_loss: 0.6386 - val_acc: 0.7167\n",
      "Epoch 63/80\n",
      "50/50 [==============================] - 26s 511ms/step - loss: 0.1354 - acc: 0.9645 - val_loss: 0.5276 - val_acc: 0.8167\n",
      "Epoch 64/80\n",
      "50/50 [==============================] - 26s 518ms/step - loss: 0.2203 - acc: 0.9213 - val_loss: 0.4627 - val_acc: 0.8333\n",
      "Epoch 65/80\n",
      "50/50 [==============================] - 27s 532ms/step - loss: 0.1144 - acc: 0.9645 - val_loss: 0.4135 - val_acc: 0.8500\n",
      "Epoch 66/80\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 0.1267 - acc: 0.9569 - val_loss: 0.5490 - val_acc: 0.8167\n",
      "Epoch 67/80\n",
      "50/50 [==============================] - 26s 529ms/step - loss: 0.1471 - acc: 0.9467 - val_loss: 0.5745 - val_acc: 0.7500\n",
      "Epoch 68/80\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 0.1434 - acc: 0.9518 - val_loss: 0.5402 - val_acc: 0.7667\n",
      "Epoch 69/80\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 0.1466 - acc: 0.9442 - val_loss: 0.6464 - val_acc: 0.8167\n",
      "Epoch 70/80\n",
      "50/50 [==============================] - 27s 532ms/step - loss: 0.1970 - acc: 0.9239 - val_loss: 0.9623 - val_acc: 0.7000\n",
      "Epoch 71/80\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 0.2131 - acc: 0.9213 - val_loss: 1.6666 - val_acc: 0.6000\n",
      "Epoch 72/80\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 0.1322 - acc: 0.9543 - val_loss: 0.5998 - val_acc: 0.8000\n",
      "Epoch 73/80\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 0.0821 - acc: 0.9721 - val_loss: 0.6062 - val_acc: 0.8333\n",
      "Epoch 74/80\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 0.1082 - acc: 0.9594 - val_loss: 0.6525 - val_acc: 0.8000\n",
      "Epoch 75/80\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 0.1262 - acc: 0.9645 - val_loss: 0.6309 - val_acc: 0.7833\n",
      "Epoch 76/80\n",
      "50/50 [==============================] - 26s 530ms/step - loss: 0.1763 - acc: 0.9365 - val_loss: 0.6691 - val_acc: 0.7667\n",
      "Epoch 77/80\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 0.1075 - acc: 0.9594 - val_loss: 0.7006 - val_acc: 0.8333\n",
      "Epoch 78/80\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 0.1427 - acc: 0.9569 - val_loss: 0.9521 - val_acc: 0.7167\n",
      "Epoch 79/80\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 0.1931 - acc: 0.9289 - val_loss: 0.7510 - val_acc: 0.7833\n",
      "Epoch 80/80\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 0.2932 - acc: 0.8959 - val_loss: 0.7396 - val_acc: 0.7333\n"
     ]
    }
   ],
   "source": [
    "# Define some callbacks to improve training.\n",
    "#early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Define modifiable training hyperparameters.\n",
    "epochs = 80\n",
    "\n",
    "# Fit the model to the training data using a generator.\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    #callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.6983 - acc: 0.7826\n",
      "test loss, test acc: [0.6983227729797363, 0.782608687877655]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_ds, batch_size=batch_size)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot_utils import plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-ml-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39ae795c3b6613b3a9cfc085ce713292b6eefc863ced5f4a8404447c67e159c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
