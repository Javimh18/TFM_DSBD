{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/javiermunoz/Universidad/MasterDSyBD/TFM/TFM_DSBD'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# Changing the working directory\n",
    "os.chdir('../..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc(\"figure\", figsize=(15, 5))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>path_to_model</th>\n",
       "      <th>subset_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mediapipe</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>77.0</td>\n",
       "      <td>src/mediapipe/bestmodels/best_mp_77_0.92_model.h5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>convlstm</td>\n",
       "      <td>simple</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>39.0</td>\n",
       "      <td>src/convlstm/bestmodels/best_simple_39_0.93_mo...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>convlstm</td>\n",
       "      <td>stateless</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>22.0</td>\n",
       "      <td>src/convlstm/bestmodels/best_stateless_22_0.95...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3DCNN</td>\n",
       "      <td>3dcnn</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>63.0</td>\n",
       "      <td>src/3DCNN/bestmodels/best_3dcnn_63_0.90_model.h5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type model_name  train_acc  val_acc  test_acc  train_loss  val_loss  \\\n",
       "0  mediapipe         mp       0.95     0.92      0.93        0.22      0.28   \n",
       "1   convlstm     simple       0.96     0.93      0.93        0.15      0.20   \n",
       "2   convlstm  stateless       0.93     0.95      0.91        0.22      0.19   \n",
       "3      3DCNN      3dcnn       0.92     0.90      0.87        0.35      0.39   \n",
       "\n",
       "   test_loss  epoch                                      path_to_model  \\\n",
       "0       0.28   77.0  src/mediapipe/bestmodels/best_mp_77_0.92_model.h5   \n",
       "1       0.19   39.0  src/convlstm/bestmodels/best_simple_39_0.93_mo...   \n",
       "2       0.19   22.0  src/convlstm/bestmodels/best_stateless_22_0.95...   \n",
       "3       0.42   63.0   src/3DCNN/bestmodels/best_3dcnn_63_0.90_model.h5   \n",
       "\n",
       "   subset_size  \n",
       "0         10.0  \n",
       "1         10.0  \n",
       "2         10.0  \n",
       "3         10.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard = pd.read_csv(\"data/leaderboard.csv\")\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 20, 128)           916992    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20, 256)           394240    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 20, 256)           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 20, 128)           197120    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 20, 128)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,560,170\n",
      "Trainable params: 1,560,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "path_to_test = leaderboard['path_to_model'][0]\n",
    "\n",
    "model_to_test = tf.keras.models.load_model(path_to_test)\n",
    "model_to_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Barbecue': 0,\n",
       " 'Birthday': 1,\n",
       " 'Buy': 2,\n",
       " 'Chewing-gum': 3,\n",
       " 'Coin': 4,\n",
       " 'Milk': 5,\n",
       " 'Mock': 6,\n",
       " 'Realize': 7,\n",
       " 'Sweet milk': 8,\n",
       " 'To land': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils import load_dict\n",
    "subset = 10\n",
    "labels=load_dict(f'data/subset_{subset}_lsa_64/pickl_files/labels_map.pkl')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from numpy.random import default_rng\n",
    "from src.config import LM_PER_VIDEO\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "\n",
    "rng = default_rng()\n",
    "\n",
    "def get_landmarks(frames: list):\n",
    "    \n",
    "    landmarks_to_model=[]\n",
    "    extracted_n_lm_idx = sorted(rng.choice(len(frames), size=LM_PER_VIDEO, replace=False))\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        for i in range(len(frames)):\n",
    "            if i in extracted_n_lm_idx:\n",
    "                results = holistic.process(frames[i])\n",
    "                if results is None:\n",
    "                    print(\"Something is wrong w/ mediapipe... Exiting.\")\n",
    "                    return None\n",
    "                \n",
    "                landmarks_to_model.append(results)\n",
    "    \n",
    "    return np.array(landmarks_to_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type type).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m landmarks_to_model \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     exit()\n\u001b[0;32m---> 20\u001b[0m logits \u001b[39m=\u001b[39m model_to_test\u001b[39m.\u001b[39;49mpredict(np\u001b[39m.\u001b[39;49mexpand_dims(landmarks_to_model, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m))\n\u001b[1;32m     21\u001b[0m pred_label \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(labels\u001b[39m.\u001b[39mvalues())\u001b[39m.\u001b[39mindex(np\u001b[39m.\u001b[39margmax(logits))\n\u001b[1;32m     22\u001b[0m cv2\u001b[39m.\u001b[39mputText(frame, pred_label)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev-ml-environment/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev-ml-environment/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type type)."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "frames_to_analyze=[]\n",
    "count=1 \n",
    "ret=True\n",
    "while ret:\n",
    "    ret, frame = cap.read()\n",
    "    frames_to_analyze.append(frame)\n",
    "    if count % 100 == 0:\n",
    "        landmarks_to_model = get_landmarks(frames_to_analyze)\n",
    "        if landmarks_to_model is None:\n",
    "            exit()\n",
    "        logits = model_to_test.predict(np.expand_dims(landmarks_to_model, axis=0))\n",
    "        pred_label = list(labels.values()).index(np.argmax(logits))\n",
    "        cv2.putText(frame, pred_label)\n",
    "\n",
    "    count += 1\n",
    "    # Show to screen\n",
    "    cv2.imshow('OpenCV Feed', frame)\n",
    "\n",
    "    # Break gracefully\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
