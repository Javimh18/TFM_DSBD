{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/javiermunoz/Universidad/MasterDSyBD/TFM/TFM_DSBD'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# Changing the working directory\n",
    "os.chdir('../..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc(\"figure\", figsize=(15, 5))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>path_to_model</th>\n",
       "      <th>subset_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convlstm</td>\n",
       "      <td>simple</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>39.0</td>\n",
       "      <td>src/convlstm/bestmodels/best_simple_39_0.93_10...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>convlstm</td>\n",
       "      <td>stateless</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>22.0</td>\n",
       "      <td>src/convlstm/bestmodels/best_stateless_22_0.95...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mediapipe</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.54</td>\n",
       "      <td>178.0</td>\n",
       "      <td>src/mediapipe/bestmodels/best_mp_178_0.90_mode...</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mediapipe</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.43</td>\n",
       "      <td>159.0</td>\n",
       "      <td>src/mediapipe/bestmodels/best_mp_159_0.85_mode...</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mediapipe</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.55</td>\n",
       "      <td>167.0</td>\n",
       "      <td>src/mediapipe/bestmodels/best_mp_167_0.86_mode...</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3DCNN</td>\n",
       "      <td>3dcnn</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>132.0</td>\n",
       "      <td>src/3DCNN/bestmodels/best_3dcnn_132_0.92_model.h5</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>convlstm</td>\n",
       "      <td>stateless</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>63.0</td>\n",
       "      <td>src/convlstm/bestmodels/best_stateless_63_0.94...</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>convlstm</td>\n",
       "      <td>stateless</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.46</td>\n",
       "      <td>93.0</td>\n",
       "      <td>src/convlstm/bestmodels/best_stateless_91_0.92...</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>convlstm</td>\n",
       "      <td>stateless</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>104.0</td>\n",
       "      <td>src/convlstm/bestmodels/best_stateless_104_0.7...</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>convlstm</td>\n",
       "      <td>simple</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.27</td>\n",
       "      <td>170.0</td>\n",
       "      <td>src/convlstm/bestmodels/best_simple_170_0.65_m...</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3DCNN</td>\n",
       "      <td>3dcnn</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.57</td>\n",
       "      <td>135.0</td>\n",
       "      <td>src/3DCNN/bestmodels/best_3dcnn_135_0.91_model.h5</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mediapipe</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.57</td>\n",
       "      <td>13.18</td>\n",
       "      <td>168.0</td>\n",
       "      <td>src/mediapipe/bestmodels/best_mp_168_0.84_mode...</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>convlstm</td>\n",
       "      <td>simple</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.36</td>\n",
       "      <td>72.0</td>\n",
       "      <td>src/convlstm/bestmodels/best_simple_72_0.93_mo...</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>convlstm</td>\n",
       "      <td>simple</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.52</td>\n",
       "      <td>96.0</td>\n",
       "      <td>src/convlstm/bestmodels/best_simple_96_0.89_mo...</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type model_name  train_acc  val_acc  test_acc  train_loss  val_loss  \\\n",
       "0    convlstm     simple       0.96     0.93      0.93        0.15      0.20   \n",
       "1    convlstm  stateless       0.93     0.95      0.91        0.22      0.19   \n",
       "2   mediapipe         mp       0.90     0.90      0.87        0.27      0.35   \n",
       "3   mediapipe         mp       0.89     0.85      0.85        0.38      0.62   \n",
       "4   mediapipe         mp       0.93     0.86      0.86        0.24      0.63   \n",
       "5       3DCNN      3dcnn       0.93     0.92      0.91        0.33      0.37   \n",
       "6    convlstm  stateless       0.90     0.94      0.92        0.27      0.24   \n",
       "7    convlstm  stateless       0.95     0.92      0.82        0.20      0.26   \n",
       "8    convlstm  stateless       0.87     0.77      0.74        0.38      1.05   \n",
       "9    convlstm     simple       0.83     0.65      0.65        0.48      1.36   \n",
       "10      3DCNN      3dcnn       0.91     0.91      0.88        0.45      0.50   \n",
       "11  mediapipe         mp       0.91     0.84      0.04        0.30      0.57   \n",
       "12   convlstm     simple       0.94     0.93      0.89        0.15      0.26   \n",
       "13   convlstm     simple       0.91     0.89      0.85        0.26      0.38   \n",
       "\n",
       "    test_loss  epoch                                      path_to_model  \\\n",
       "0        0.19   39.0  src/convlstm/bestmodels/best_simple_39_0.93_10...   \n",
       "1        0.19   22.0  src/convlstm/bestmodels/best_stateless_22_0.95...   \n",
       "2        0.54  178.0  src/mediapipe/bestmodels/best_mp_178_0.90_mode...   \n",
       "3        0.43  159.0  src/mediapipe/bestmodels/best_mp_159_0.85_mode...   \n",
       "4        0.55  167.0  src/mediapipe/bestmodels/best_mp_167_0.86_mode...   \n",
       "5        0.40  132.0  src/3DCNN/bestmodels/best_3dcnn_132_0.92_model.h5   \n",
       "6        0.22   63.0  src/convlstm/bestmodels/best_stateless_63_0.94...   \n",
       "7        0.46   93.0  src/convlstm/bestmodels/best_stateless_91_0.92...   \n",
       "8        1.06  104.0  src/convlstm/bestmodels/best_stateless_104_0.7...   \n",
       "9        1.27  170.0  src/convlstm/bestmodels/best_simple_170_0.65_m...   \n",
       "10       0.57  135.0  src/3DCNN/bestmodels/best_3dcnn_135_0.91_model.h5   \n",
       "11      13.18  168.0  src/mediapipe/bestmodels/best_mp_168_0.84_mode...   \n",
       "12       0.36   72.0  src/convlstm/bestmodels/best_simple_72_0.93_mo...   \n",
       "13       0.52   96.0  src/convlstm/bestmodels/best_simple_96_0.89_mo...   \n",
       "\n",
       "    subset_size  \n",
       "0          10.0  \n",
       "1          10.0  \n",
       "2          20.0  \n",
       "3          40.0  \n",
       "4          30.0  \n",
       "5          20.0  \n",
       "6          20.0  \n",
       "7          30.0  \n",
       "8          40.0  \n",
       "9          40.0  \n",
       "10         40.0  \n",
       "11         50.0  \n",
       "12         20.0  \n",
       "13         30.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard = pd.read_csv(\"data/leaderboard.csv\")\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'einops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m WIDTH \u001b[39m=\u001b[39m \u001b[39m224\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframe_generator\u001b[39;00m \u001b[39mimport\u001b[39;00m FrameGenerator\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mblocks\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv2Plus1D, ResizeVideo, add_residual_block\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m DATA_PATH, SPLITS\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplot_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_history\n",
      "File \u001b[0;32m~/Universidad/MasterDSyBD/TFM/TFM_DSBD/src/3DCNN/blocks.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39meinops\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mConv2Plus1D\u001b[39;00m(keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLayer):\n\u001b[1;32m      6\u001b[0m   \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, filters, kernel_size, padding):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'einops'"
     ]
    }
   ],
   "source": [
    "# Define the dimensions of one frame in the set of frames created\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "\n",
    "from src.frame_generator import FrameGenerator\n",
    "from blocks import Conv2Plus1D, ResizeVideo, add_residual_block\n",
    "from src.config import DATA_PATH, SPLITS\n",
    "from src.plot_utils import plot_history\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "input_shape = (None, 10, HEIGHT, WIDTH, 3)\n",
    "input = layers.Input(shape=(input_shape[1:]))\n",
    "x = input\n",
    "\n",
    "x = Conv2Plus1D(filters=16, kernel_size=(3, 7, 7), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = ResizeVideo(HEIGHT // 2, WIDTH // 2)(x)\n",
    "\n",
    "# Block 1\n",
    "x = add_residual_block(x, 16, (3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT // 4, WIDTH // 4)(x)\n",
    "\n",
    "# Block 2\n",
    "x = add_residual_block(x, 32, (3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT // 8, WIDTH // 8)(x)\n",
    "\n",
    "# Block 3\n",
    "x = add_residual_block(x, 64, (3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT // 16, WIDTH // 16)(x)\n",
    "\n",
    "# Block 4\n",
    "x = add_residual_block(x, 128, (3, 3, 3))\n",
    "\n",
    "x = layers.GlobalAveragePooling3D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(10)(x)\n",
    "\n",
    "model_to_test = keras.Model(input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_test.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer = keras.optimizers.Adam(learning_rate = 0.0001), \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 224, 22  0           []                               \n",
      "                                4, 3)]                                                            \n",
      "                                                                                                  \n",
      " conv2_plus1d (Conv2Plus1D)     (None, 10, 224, 224  3152        ['input_1[0][0]']                \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 10, 224, 224  64         ['conv2_plus1d[0][0]']           \n",
      " alization)                     , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 10, 224, 224  0           ['batch_normalization[0][0]']    \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " resize_video (ResizeVideo)     (None, 10, 112, 112  0           ['re_lu[0][0]']                  \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " residual_main (ResidualMain)   (None, 10, 112, 112  6272        ['resize_video[0][0]']           \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 10, 112, 112  0           ['resize_video[0][0]',           \n",
      "                                , 16)                             'residual_main[0][0]']          \n",
      "                                                                                                  \n",
      " resize_video_1 (ResizeVideo)   (None, 10, 56, 56,   0           ['add[0][0]']                    \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " project (Project)              (None, 10, 56, 56,   608         ['resize_video_1[0][0]']         \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " residual_main_1 (ResidualMain)  (None, 10, 56, 56,   20224      ['resize_video_1[0][0]']         \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 10, 56, 56,   0           ['project[0][0]',                \n",
      "                                32)                               'residual_main_1[0][0]']        \n",
      "                                                                                                  \n",
      " resize_video_2 (ResizeVideo)   (None, 10, 28, 28,   0           ['add_1[0][0]']                  \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " project_1 (Project)            (None, 10, 28, 28,   2240        ['resize_video_2[0][0]']         \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " residual_main_2 (ResidualMain)  (None, 10, 28, 28,   80384      ['resize_video_2[0][0]']         \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 10, 28, 28,   0           ['project_1[0][0]',              \n",
      "                                64)                               'residual_main_2[0][0]']        \n",
      "                                                                                                  \n",
      " resize_video_3 (ResizeVideo)   (None, 10, 14, 14,   0           ['add_2[0][0]']                  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " project_2 (Project)            (None, 10, 14, 14,   8576        ['resize_video_3[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " residual_main_3 (ResidualMain)  (None, 10, 14, 14,   320512     ['resize_video_3[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 10, 14, 14,   0           ['project_2[0][0]',              \n",
      "                                128)                              'residual_main_3[0][0]']        \n",
      "                                                                                                  \n",
      " global_average_pooling3d (Glob  (None, 128)         0           ['add_3[0][0]']                  \n",
      " alAveragePooling3D)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 128)          0           ['global_average_pooling3d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10)           1290        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 443,322\n",
      "Trainable params: 443,290\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_to_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_3dcnn_weights = leaderboard['path_to_model'][3]\n",
    "model_to_test.load_weights(path_to_3dcnn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Barbecue': 0,\n",
       " 'Birthday': 1,\n",
       " 'Buy': 2,\n",
       " 'Chewing-gum': 3,\n",
       " 'Coin': 4,\n",
       " 'Milk': 5,\n",
       " 'Mock': 6,\n",
       " 'Realize': 7,\n",
       " 'Sweet milk': 8,\n",
       " 'To land': 9}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils import load_dict\n",
    "subset = 10\n",
    "labels=load_dict(f'data/subset_{subset}_lsa_64/pickl_files/labels_map.pkl')\n",
    "labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference based on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"/home/javiermunoz/TFM_DSBD/data/subset_10_lsa_64/test/Mock/029_001_004.mp4\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when replace is False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m     23\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m---> 25\u001b[0m frames2extract_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39msorted\u001b[39m(rng\u001b[39m.\u001b[39;49mchoice(\u001b[39mlen\u001b[39;49m(captured_frames), size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, replace\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)))\n\u001b[1;32m     27\u001b[0m frames_to_predict \u001b[39m=\u001b[39m []\n\u001b[1;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(captured_frames)):\n",
      "File \u001b[0;32m_generator.pyx:769\u001b[0m, in \u001b[0;36mnumpy.random._generator.Generator.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when replace is False"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from src.load_dataset_aux import format_frames\n",
    "from numpy.random import default_rng\n",
    "\n",
    "rng = default_rng()\n",
    "threshold = 0.7\n",
    "output_size = (224,224)\n",
    "\n",
    "cap = cv2.VideoCapture('/home/javiermunoz/TFM_DSBD/data/subset_10_lsa_64/test/Mock/029_001_004.mp4')\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "captured_frames=[]\n",
    "count=1 \n",
    "ret=True\n",
    "while ret:\n",
    "    ret, frame = cap.read()\n",
    "    captured_frames.append(frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "frames2extract_idx = np.array(sorted(rng.choice(len(captured_frames), size=10, replace=False)))\n",
    "\n",
    "frames_to_predict = []\n",
    "for i in range(len(captured_frames)):\n",
    "    if i in frames2extract_idx:\n",
    "        frames_to_predict.append(captured_frames[i])\n",
    "\n",
    "result = []\n",
    "for frame in frames_to_predict:\n",
    "    frame_formatted = format_frames(frame, output_size)\n",
    "    result.append(frame_formatted)\n",
    "\n",
    "result = np.array(result)[..., [2,1,0]]\n",
    "\n",
    "logits = model_to_test.predict(np.expand_dims(result, axis=0))\n",
    "pred_probs = tf.nn.softmax(logits, axis=1).numpy()\n",
    "print(pred_probs)\n",
    "\n",
    "if pred_probs[pred_probs > threshold].any():\n",
    "    pred = np.argmax(pred_probs)\n",
    "    pred_label = [k for k, v in labels.items() if v == pred]\n",
    "    print(pred_label)\n",
    "\n",
    "captured_frames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference based on video camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_to_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m     result\u001b[39m.\u001b[39mappend(frame_formatted)\n\u001b[1;32m     35\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result)[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, [\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m]]\n\u001b[0;32m---> 37\u001b[0m logits \u001b[39m=\u001b[39m model_to_test\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39mexpand_dims(result, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[1;32m     38\u001b[0m pred_probs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msoftmax(logits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     39\u001b[0m \u001b[39mprint\u001b[39m(pred_probs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_to_test' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from src.load_dataset_aux import format_frames\n",
    "from numpy.random import default_rng\n",
    "\n",
    "rng = default_rng()\n",
    "threshold = 0.7\n",
    "output_size = (224,224)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "captured_frames=[]\n",
    "count=1 \n",
    "ret=True\n",
    "while ret:\n",
    "    ret, frame = cap.read()\n",
    "    captured_frames.append(frame)\n",
    "    if count % 80 == 0:\n",
    "        frames2extract_idx = np.array(sorted(rng.choice(len(captured_frames), size=10, replace=False)))\n",
    "        \n",
    "        frames_to_predict = []\n",
    "        for i in range(len(captured_frames)):\n",
    "            if i in frames2extract_idx:\n",
    "                frames_to_predict.append(captured_frames[i])\n",
    "\n",
    "\n",
    "        result = []\n",
    "        for frame in frames_to_predict:\n",
    "            frame_formatted = format_frames(frame, output_size)\n",
    "            result.append(frame_formatted)\n",
    "        \n",
    "        result = np.array(result)[..., [2,1,0]]\n",
    "\n",
    "        logits = model_to_test.predict(np.expand_dims(result, axis=0))\n",
    "        pred_probs = tf.nn.softmax(logits, axis=1).numpy()\n",
    "        print(pred_probs)\n",
    "        if pred_probs[pred_probs > threshold].any():\n",
    "            pred = np.argmax(pred_probs)\n",
    "            pred_label = [k for k, v in labels.items() if v == pred]\n",
    "            print(pred_label)\n",
    "\n",
    "        captured_frames = []\n",
    "\n",
    "    count += 1\n",
    "    # Show to screen\n",
    "    cv2.imshow('OpenCV Feed', frame)\n",
    "\n",
    "    # Break gracefully\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
