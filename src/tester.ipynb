{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import config\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "from mp_funs import extract_landmarks_to_np, FACEMESH_LANDMARKS, POSE_LANDMARKS, HAND_LANDMARKS\n",
    "from utils import save_dict, load_dict\n",
    "from math import floor\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTENSION = '.mp4'\n",
    "SPLITS = ['train', 'val', 'test']\n",
    "X_PICK_FILE_PATH = 'data/npy_videos/npy_db_x.pkl'\n",
    "Y_PICK_FILE_PATH = 'data/npy_videos/npy_db_y.pkl'\n",
    "LABELS_MAP_PICK_FILE_PATH = 'data/npy_videos/labels_map.pkl'\n",
    "\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities that will be useful for action representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_gloss(indexfile='data/WLASL_v0.3.json'):\n",
    "    content = json.load(open(indexfile))\n",
    "    return len([items for items in content])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_gloss(indexfile='../data/WLASL_v0.3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_error_info(func, path, _):\n",
    "    print(\"INFO: The path\", path, \"does not exist. Skipping...\")\n",
    "\n",
    "def gloss_ranking(content, vid_directory, top_k):\n",
    "    ranking = {}\n",
    "    for entry in content:\n",
    "        gloss = entry['gloss']\n",
    "        \n",
    "        appereances = []\n",
    "        for split in SPLITS:\n",
    "            path_to_check = os.path.join(vid_directory, split, gloss)\n",
    "            # If there is a gloss that does not appear in a split, we skip it\n",
    "            try:\n",
    "                items = os.listdir(path_to_check)\n",
    "                appereances.append(len(items))\n",
    "            except OSError:\n",
    "                appereances.append(0)\n",
    "\n",
    "        # we add up all the videos from each split, given a gloss\n",
    "        ranking[gloss] = sum(appereances)\n",
    "\n",
    "    # sorting the dictionary based on the value\n",
    "    top_ranking = {k: v for k, v in sorted(ranking.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    return dict(itertools.islice(top_ranking.items(), top_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_dict_to_tensor(X):\n",
    "    max_len = -10e8\n",
    "    n_frame_lm = FACEMESH_LANDMARKS + POSE_LANDMARKS + 2*HAND_LANDMARKS\n",
    "\n",
    "    for sp in SPLITS:\n",
    "        split = X[sp]\n",
    "        for video in split:\n",
    "            cur_len = len(video)\n",
    "            if cur_len > max_len:\n",
    "                max_len = cur_len\n",
    "\n",
    "    # once we got the max_len, we expland the videos to match the frames\n",
    "    dims = {}\n",
    "    for sp in SPLITS:\n",
    "        split = X[sp]\n",
    "        for video in split:\n",
    "            diff = max_len - len(video)\n",
    "            if diff != 0:\n",
    "                if diff % 2 != 0:\n",
    "                    # insert at the end of the list\n",
    "                    for i in range(0, floor(diff/2)):\n",
    "                        video.append(np.zeros(n_frame_lm))\n",
    "                    \n",
    "                    # insert at the beginning of the list\n",
    "                    for i in range(0, floor(diff/2)+1):\n",
    "                        video.insert(i, np.zeros(n_frame_lm))\n",
    "                else:\n",
    "                    # insert at the end and the beginning of the list\n",
    "                    for i in range(0, int(diff/2)):\n",
    "                        video.append(np.zeros(n_frame_lm))\n",
    "                        video.insert(i, np.zeros(n_frame_lm))\n",
    "        \n",
    "    for sp in SPLITS:\n",
    "        # Retrieve the dimensions from the tensors\n",
    "        dims[sp] = (len(X[sp]), max_len, n_frame_lm)\n",
    "        # flatten the nested list of np.arrays \n",
    "        X[sp] = np.concatenate(X[sp]).ravel()\n",
    "        \n",
    "    # Now that the number of frames between videos are matched, we cast them into tensors\n",
    "    for sp in SPLITS:\n",
    "        X[sp] = torch.tensor(X[sp]).reshape(dims[sp])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels):\n",
    "    new_labels = {}\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(labels['train'])\n",
    "\n",
    "    for sp in SPLITS:\n",
    "        new_labels[sp] = torch.tensor(le.transform(labels[sp]))\n",
    "\n",
    "    le_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "    return new_labels, le_mapping \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(X_tens, Y_enc, le_mapping):\n",
    "    save_dict(X_tens, X_PICK_FILE_PATH)\n",
    "    save_dict(Y_enc, Y_PICK_FILE_PATH)\n",
    "    save_dict(le_mapping, LABELS_MAP_PICK_FILE_PATH)\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    X_tens = load_dict(X_PICK_FILE_PATH)\n",
    "    Y_enc = load_dict(Y_PICK_FILE_PATH)\n",
    "    le_mapping = load_dict(LABELS_MAP_PICK_FILE_PATH)\n",
    "    return X_tens, Y_enc, le_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def organize(indexfile='data/WLASL_v0.3.json', vid_directory='data/videos', top_k = 1000):\n",
    "    if indexfile == 'nil':\n",
    "        print('No index specified. Exiting.')\n",
    "        return\n",
    "\n",
    "    content = json.load(open(indexfile))\n",
    "\n",
    "    if top_k > get_n_gloss(indexfile):\n",
    "        print(\"The number of the top_k is greater the total glosses of the dataset\")\n",
    "        return\n",
    "    \n",
    "    gloss_rank = gloss_ranking(content, vid_directory, top_k)\n",
    "    print(\"Ranking created with top\", top_k, \"glosses/labels...\")\n",
    "\n",
    "    for entry in content:\n",
    "        gloss = entry['gloss']\n",
    "        instances = entry['instances']\n",
    "\n",
    "        # if the gloss is in the top_k, then we add it to the top_k dataset\n",
    "        if gloss in gloss_rank.keys():\n",
    "            for inst in instances:\n",
    "                vid_id = inst['video_id']\n",
    "                split = inst['split']\n",
    "\n",
    "                source = os.path.join(vid_directory, vid_id+EXTENSION)\n",
    "                destination = os.path.join(vid_directory, f\"top_{top_k}\", split, gloss)\n",
    "\n",
    "                # create the dataset structure /data/videos/top_k/<train|test|val>/gloss\n",
    "                if not os.path.exists(destination): \n",
    "                    os.makedirs(destination)\n",
    "                \n",
    "                # and now, we copy from /data/videos to /data/videos/top_k/<train|test|val>/gloss\n",
    "                if os.path.exists(source):\n",
    "                    shutil.copy(source, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking created with top 10 glosses/labels...\n"
     ]
    }
   ],
   "source": [
    "# organize(indexfile='../data/WLASL_v0.3.json', vid_directory='../data/videos', top_k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../data/videos/top_200/train/'\n",
    "folders = list(os.walk(root))[1:]\n",
    "\n",
    "for folder in folders:\n",
    "    if not folder[2]:\n",
    "        print(folder[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-ml-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
